{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5dK/YiC9WzRJje8WMSOKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vatoer/pu-sentiment/blob/main/indoBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "02RddFBZQFtd",
        "outputId": "530466bd-6401-4056-b6dd-12c0ef2e8504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31923, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"translated_sentiment_data.csv\", sep=\",\")\n",
        "\n",
        "# Select the text column and the target column\n",
        "text_column = \"translated_text\"\n",
        "target_column = \"Sentiment\"\n",
        "\n",
        "# Handle NaN values\n",
        "df[target_column] = df[target_column].fillna(0).astype(int)\n",
        "\n",
        "# Load the pre-trained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"indolem/indobert-base-uncased\")\n",
        "\n",
        "# Create a custom dataset\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        label = self.labels[idx]\n",
        "        label_shifted = int(label + 1)  # Convert label_shifted to an integer\n",
        "        one_hot_label = torch.zeros(3)  # 3 classes\n",
        "        one_hot_label[label_shifted] = 1\n",
        "        item['labels'] = one_hot_label\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create training and testing datasets\n",
        "train_dataset = SentimentDataset(tokenizer(train_df['clean_text'].astype(str).tolist(), padding=True, truncation=True, max_length=512), train_df[target_column].tolist())\n",
        "test_dataset = SentimentDataset(tokenizer(test_df['clean_text'].astype(str).tolist(), padding=True, truncation=True, max_length=512), test_df[target_column].tolist())\n",
        "\n",
        "# Create training and testing data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"indolem/indobert-base-uncased\", num_labels=3)\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    for batch in dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n"
      ],
      "metadata": {
        "id": "-D0BimSrYhwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, optimizer, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s2-RgTsYdyC",
        "outputId": "abe283f4-eb44-4acf-8d33-360a4a690d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "Epoch 2/3\n",
            "Epoch 3/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            logits = outputs.logits\n",
        "            predicted = torch.argmax(logits, dim=-1)\n",
        "            # Convert true_labels to binary targets\n",
        "            true_labels.extend(torch.argmax(batch['labels'], dim=-1).cpu().numpy())\n",
        "            predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "vEm-czqEYOhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the testing set\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1-Score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbPfFOWfYVUP",
        "outputId": "c094fb80-e2c0-4ffa-fe77-067ee4f498e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8958\n",
            "Test Precision: 0.8665\n",
            "Test Recall: 0.8958\n",
            "Test F1-Score: 0.8717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text, model, tokenizer, device):\n",
        "    \"\"\"Predicts the sentiment of a given text using the trained model.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to analyze.\n",
        "        model (transformers.AutoModelForSequenceClassification): The trained sentiment analysis model.\n",
        "        tokenizer (transformers.AutoTokenizer): The tokenizer used for the model.\n",
        "        device (torch.device): The device to run the model on (CPU or GPU).\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted sentiment label (\"negative\", \"neutral\", or \"positive\").\n",
        "    \"\"\"\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "    # Move inputs to the device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Get model predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predicted_label = torch.argmax(outputs.logits, dim=-1).item()\n",
        "\n",
        "    # Map label to sentiment\n",
        "    sentiment_mapping = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "    predicted_sentiment = sentiment_mapping[predicted_label]\n",
        "\n",
        "    return predicted_sentiment\n",
        "\n"
      ],
      "metadata": {
        "id": "HPzAoMNWazhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "tweet = \"banyak korupsi #kabinetMerahPutih\"\n",
        "predicted_sentiment = predict_sentiment(tweet, model, tokenizer, device)\n",
        "print(f\"Predicted sentiment: {predicted_sentiment}\")\n",
        "\n",
        "# Example usage:\n",
        "tweet = \"Kabinet baru dilantik di istana negara\"\n",
        "predicted_sentiment = predict_sentiment(tweet, model, tokenizer, device)\n",
        "print(f\"Predicted sentiment: {predicted_sentiment}\")\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "tweet = \"selamat untuk kabinet yang baru, semoga Indonesia makin maju\"\n",
        "predicted_sentiment = predict_sentiment(tweet, model, tokenizer, device)\n",
        "print(f\"Predicted sentiment: {predicted_sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il65H-uAbBUn",
        "outputId": "a0f6111d-47f3-400b-8a3a-fec5043aa842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "Predicted sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U0Woexgla6dN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}